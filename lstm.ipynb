{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import gc\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "from scipy.fftpack import fft\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import keras\n",
    "from keras import optimizers\n",
    "from keras.layers import Conv2D, BatchNormalization, MaxPooling2D, Dense, Input, Dropout, Flatten, Activation, Conv1D, LSTM\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.initializers import Constant\n",
    "from keras.initializers import he_normal, he_uniform\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.regularizers import l2\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seems to reduce the chance of gpu errors, also doesn't blindly allocate all vram \n",
    "\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_specgram(audio, sample_rate, window_size=20,\n",
    "                 step_size=10, eps=1e-10):\n",
    "    nperseg = int(round(window_size * sample_rate / 1e3))\n",
    "    noverlap = int(round(step_size * sample_rate / 1e3))\n",
    "    freqs, times, spec = signal.spectrogram(audio,\n",
    "                                    fs=sample_rate,\n",
    "                                    window='hann',\n",
    "                                    nperseg=nperseg,\n",
    "                                    noverlap=noverlap,\n",
    "                                    detrend=False)\n",
    "    return freqs, times, np.log(spec.T.astype(np.float32) + eps)\n",
    "\n",
    "def list_wavs_fname(dirpath, ext='wav'):\n",
    "    fpaths = glob(os.path.join(dirpath, r'*/*' + ext))\n",
    "    pat = r'.+\\\\(\\w+)\\\\\\w+\\.wav$'\n",
    "    labels = []\n",
    "    for fpath in fpaths:\n",
    "        r = re.match(pat, fpath)\n",
    "        if r:\n",
    "            labels.append(r.group(1))\n",
    "    pat = r'.+\\\\(\\w+\\.wav)$'\n",
    "    fnames = []\n",
    "    for fpath in fpaths:\n",
    "        r = re.match(pat, fpath)\n",
    "        if r:\n",
    "            fnames.append(r.group(1))\n",
    "    return labels, fnames\n",
    "\n",
    "def pad_audio(samples):\n",
    "    if len(samples) >= L: return samples\n",
    "    else: return np.pad(samples, pad_width=(L - len(samples), 0), mode='constant', constant_values=(0, 0))\n",
    "\n",
    "def chop_audio(samples, L=16000, num=20):\n",
    "    for i in range(num):\n",
    "        beg = np.random.randint(0, len(samples) - L)\n",
    "        yield samples[beg: beg + L]\n",
    "\n",
    "def label_transform(labels):\n",
    "    nlabels = []\n",
    "    for label in labels:\n",
    "        if label == '_background_noise_':\n",
    "            nlabels.append('silence')\n",
    "        elif label not in legal_labels:\n",
    "            nlabels.append('unknown')\n",
    "        else:\n",
    "            nlabels.append(label)\n",
    "    return pd.get_dummies(pd.Series(nlabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 16000\n",
    "legal_labels = 'yes no up down left right on off stop go silence unknown'.split()\n",
    "\n",
    "#src folders\n",
    "root_path = r'.\\\\data'\n",
    "out_path = r'.'\n",
    "model_path = r'.'\n",
    "train_data_path = os.path.join(root_path, 'input', 'train', 'audio')\n",
    "test_data_path = os.path.join(root_path, 'input', 'test', 'audio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\\\data\\input\\train\\audio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\01124585\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels, fnames = list_wavs_fname(train_data_path)\n",
    "\n",
    "new_sample_rate = 16000\n",
    "y = []\n",
    "x = []\n",
    "\n",
    "for label, fname in zip(labels, fnames):\n",
    "    if label not in legal_labels and label != '_background_noise_' and np.random.randint(10) > 0:\n",
    "        continue\n",
    "    sample_rate, samples = wavfile.read(os.path.join(train_data_path, label, fname))\n",
    "    samples = pad_audio(samples)\n",
    "    if len(samples) > 16000:\n",
    "        n_samples = chop_audio(samples)\n",
    "    else: n_samples = [samples]\n",
    "    for samples in n_samples:\n",
    "        resampled = signal.resample(samples, int(new_sample_rate / sample_rate * samples.shape[0]))\n",
    "        _, _, specgram = log_specgram(resampled, sample_rate=new_sample_rate)\n",
    "        y.append(label)\n",
    "        x.append(specgram)\n",
    "x = np.array(x)\n",
    "y = label_transform(y)\n",
    "label_index = y.columns.values\n",
    "y = y.values\n",
    "y = np.array(y)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "del x, y\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cnn_lstm():\n",
    "\n",
    "#     model = Sequential()\n",
    "#     model.add(Conv1D(256, 10, strides=4, input_shape=(99, 161)))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(Dropout(0.2))\n",
    "        \n",
    "#     model.add(LSTM(128, activation='relu', return_sequences=True, dropout=0.2))\n",
    "#     model.add(LSTM(128, activation='relu', return_sequences=True, dropout=0.2))\n",
    "\n",
    "#     # 1 fully connected layer DNN ReLu with default 20% dropout\n",
    "#     model.add(Dense(64))\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(Dropout(0.2))\n",
    "    \n",
    "#     # Output layer with softmax\n",
    "#     model.add(Dense(12))\n",
    "#     model.add(Activation('softmax'))\n",
    "    \n",
    "#     return model\n",
    "\n",
    "# model = cnn_lstm()\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 99, 161)]         0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 23, 256)           412416    \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 23, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 23, 256)           0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 23, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 23, 128)           197120    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                3084      \n",
      "=================================================================\n",
      "Total params: 778,252\n",
      "Trainable params: 777,740\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN, LSTM, Bidirectional, TimeDistributed, Conv1D, ZeroPadding1D, GRU\n",
    "from tensorflow.keras.layers import Lambda, Input, Dropout, Masking, BatchNormalization, Activation\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def cnn_lstm():\n",
    "    input_data = Input(shape=(99, 161))\n",
    "\n",
    "    x = Conv1D(filters=256, kernel_size=10, strides=4)(input_data)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "        \n",
    "    x = LSTM(128, activation='relu', return_sequences=True, dropout=0.2, recurrent_dropout=0.3)(x)\n",
    "    x = LSTM(128, activation='relu', return_sequences=False, dropout=0.2, recurrent_dropout=0.4)(x)\n",
    "\n",
    "    x = Dense(units=256, activation='relu', kernel_regularizer=l2(1e-6), kernel_initializer=he_uniform())(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    # Output layer with softmax\n",
    "    y_pred = Dense(units=12, activation='softmax')(x)\n",
    "\n",
    "    network_model = Model(inputs=input_data, outputs=y_pred)\n",
    "    \n",
    "    return network_model\n",
    "\n",
    "K.clear_session()\n",
    "model = cnn_lstm()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22392 samples, validate on 5598 samples\n",
      "Epoch 1/50\n",
      "22392/22392 [==============================] - 17s 780us/sample - loss: 2.3268 - accuracy: 0.1696 - val_loss: 2.0749 - val_accuracy: 0.2133\n",
      "Epoch 2/50\n",
      "22392/22392 [==============================] - 12s 539us/sample - loss: 1.7967 - accuracy: 0.3495 - val_loss: 1.3589 - val_accuracy: 0.5341\n",
      "Epoch 3/50\n",
      "22392/22392 [==============================] - 12s 539us/sample - loss: 1.1553 - accuracy: 0.5958 - val_loss: 0.7757 - val_accuracy: 0.7512\n",
      "Epoch 4/50\n",
      "22392/22392 [==============================] - 12s 546us/sample - loss: 0.8082 - accuracy: 0.7311 - val_loss: 0.6021 - val_accuracy: 0.7997\n",
      "Epoch 5/50\n",
      "22392/22392 [==============================] - 12s 543us/sample - loss: 0.6602 - accuracy: 0.7822 - val_loss: 0.5601 - val_accuracy: 0.8114\n",
      "Epoch 6/50\n",
      "22392/22392 [==============================] - 12s 544us/sample - loss: 0.5634 - accuracy: 0.8163 - val_loss: 0.4240 - val_accuracy: 0.8635\n",
      "Epoch 7/50\n",
      "22392/22392 [==============================] - 12s 549us/sample - loss: 0.4896 - accuracy: 0.8445 - val_loss: 0.3697 - val_accuracy: 0.8775\n",
      "Epoch 8/50\n",
      "22392/22392 [==============================] - 12s 548us/sample - loss: 0.4542 - accuracy: 0.8537 - val_loss: 0.3676 - val_accuracy: 0.8766\n",
      "Epoch 9/50\n",
      "22392/22392 [==============================] - 12s 555us/sample - loss: 0.4069 - accuracy: 0.8709 - val_loss: 0.3211 - val_accuracy: 0.8944\n",
      "Epoch 10/50\n",
      "22392/22392 [==============================] - 12s 555us/sample - loss: 0.3635 - accuracy: 0.8822 - val_loss: 0.2961 - val_accuracy: 0.9076\n",
      "Epoch 11/50\n",
      "22392/22392 [==============================] - 12s 548us/sample - loss: 0.3317 - accuracy: 0.8929 - val_loss: 0.2987 - val_accuracy: 0.9041\n",
      "Epoch 12/50\n",
      "22392/22392 [==============================] - 12s 548us/sample - loss: 0.3175 - accuracy: 0.8980 - val_loss: 0.2761 - val_accuracy: 0.9126\n",
      "Epoch 13/50\n",
      "22392/22392 [==============================] - 12s 550us/sample - loss: 0.2939 - accuracy: 0.9037 - val_loss: 0.2603 - val_accuracy: 0.9164\n",
      "Epoch 14/50\n",
      "22392/22392 [==============================] - 12s 547us/sample - loss: 0.2788 - accuracy: 0.9079 - val_loss: 0.2645 - val_accuracy: 0.9182\n",
      "Epoch 15/50\n",
      "22392/22392 [==============================] - 12s 547us/sample - loss: 0.2608 - accuracy: 0.9146 - val_loss: 0.2539 - val_accuracy: 0.9212\n",
      "Epoch 16/50\n",
      "22392/22392 [==============================] - 12s 544us/sample - loss: 0.2493 - accuracy: 0.9206 - val_loss: 0.2758 - val_accuracy: 0.9135\n",
      "Epoch 17/50\n",
      "22392/22392 [==============================] - 12s 546us/sample - loss: 0.2346 - accuracy: 0.9236 - val_loss: 0.2387 - val_accuracy: 0.9277\n",
      "Epoch 18/50\n",
      "22392/22392 [==============================] - 12s 551us/sample - loss: 0.2243 - accuracy: 0.9260 - val_loss: 0.2387 - val_accuracy: 0.9278\n",
      "Epoch 19/50\n",
      "22392/22392 [==============================] - 12s 556us/sample - loss: 0.2186 - accuracy: 0.9283 - val_loss: 0.2469 - val_accuracy: 0.9241\n",
      "Epoch 20/50\n",
      "22392/22392 [==============================] - 12s 546us/sample - loss: 0.2042 - accuracy: 0.9342 - val_loss: 0.2529 - val_accuracy: 0.9271\n",
      "Epoch 21/50\n",
      "22392/22392 [==============================] - 12s 548us/sample - loss: 0.1984 - accuracy: 0.9344 - val_loss: 0.2371 - val_accuracy: 0.9289\n",
      "Epoch 22/50\n",
      "22392/22392 [==============================] - 12s 547us/sample - loss: 0.1846 - accuracy: 0.9382 - val_loss: 0.2505 - val_accuracy: 0.9296\n",
      "Epoch 23/50\n",
      "22392/22392 [==============================] - 12s 547us/sample - loss: 0.1750 - accuracy: 0.9417 - val_loss: 0.2292 - val_accuracy: 0.9334\n",
      "Epoch 24/50\n",
      "22392/22392 [==============================] - 12s 554us/sample - loss: 0.1726 - accuracy: 0.9440 - val_loss: 0.2189 - val_accuracy: 0.9355\n",
      "Epoch 25/50\n",
      "22392/22392 [==============================] - 12s 551us/sample - loss: 0.1575 - accuracy: 0.9478 - val_loss: 0.2169 - val_accuracy: 0.9394\n",
      "Epoch 26/50\n",
      "22392/22392 [==============================] - 13s 560us/sample - loss: 0.1533 - accuracy: 0.9494 - val_loss: 0.2038 - val_accuracy: 0.9411\n",
      "Epoch 27/50\n",
      "22392/22392 [==============================] - 12s 555us/sample - loss: 0.1488 - accuracy: 0.9511 - val_loss: 0.2221 - val_accuracy: 0.9382\n",
      "Epoch 28/50\n",
      "22392/22392 [==============================] - 12s 556us/sample - loss: 0.1442 - accuracy: 0.9533 - val_loss: 0.2256 - val_accuracy: 0.9337\n",
      "Epoch 29/50\n",
      "22392/22392 [==============================] - 13s 563us/sample - loss: 0.1394 - accuracy: 0.9532 - val_loss: 0.2153 - val_accuracy: 0.9377\n",
      "Epoch 30/50\n",
      "22392/22392 [==============================] - 12s 555us/sample - loss: 0.1319 - accuracy: 0.9566 - val_loss: 0.2087 - val_accuracy: 0.9414\n",
      "Epoch 31/50\n",
      "22392/22392 [==============================] - 12s 549us/sample - loss: 0.1217 - accuracy: 0.9591 - val_loss: 0.2310 - val_accuracy: 0.9378\n",
      "Epoch 32/50\n",
      "22392/22392 [==============================] - 12s 548us/sample - loss: 0.1268 - accuracy: 0.9571 - val_loss: 0.2106 - val_accuracy: 0.9437\n",
      "Epoch 33/50\n",
      "22392/22392 [==============================] - 12s 553us/sample - loss: 0.1250 - accuracy: 0.9576 - val_loss: 0.2180 - val_accuracy: 0.9437\n",
      "Epoch 34/50\n",
      "22392/22392 [==============================] - 12s 550us/sample - loss: 0.1121 - accuracy: 0.9619 - val_loss: 0.2271 - val_accuracy: 0.9393\n",
      "Epoch 35/50\n",
      "22392/22392 [==============================] - 12s 552us/sample - loss: 0.1062 - accuracy: 0.9637 - val_loss: 0.2326 - val_accuracy: 0.9366\n",
      "Epoch 36/50\n",
      "22392/22392 [==============================] - 12s 548us/sample - loss: 0.1100 - accuracy: 0.9633 - val_loss: 0.2040 - val_accuracy: 0.9425\n",
      "Epoch 37/50\n",
      "22392/22392 [==============================] - 12s 547us/sample - loss: 0.1147 - accuracy: 0.9626 - val_loss: 0.2123 - val_accuracy: 0.9441\n",
      "Epoch 38/50\n",
      "22392/22392 [==============================] - 12s 550us/sample - loss: 0.1019 - accuracy: 0.9663 - val_loss: 0.2084 - val_accuracy: 0.9466\n",
      "Epoch 39/50\n",
      "22392/22392 [==============================] - 13s 565us/sample - loss: 0.1043 - accuracy: 0.9649 - val_loss: 0.2092 - val_accuracy: 0.9468\n",
      "Epoch 40/50\n",
      "22392/22392 [==============================] - 12s 551us/sample - loss: 0.0936 - accuracy: 0.9691 - val_loss: 0.2047 - val_accuracy: 0.9489\n",
      "Epoch 41/50\n",
      "22392/22392 [==============================] - 12s 549us/sample - loss: 0.0863 - accuracy: 0.9713 - val_loss: 0.2121 - val_accuracy: 0.9471\n",
      "Epoch 42/50\n",
      "22392/22392 [==============================] - 12s 545us/sample - loss: 0.0867 - accuracy: 0.9717 - val_loss: 0.2081 - val_accuracy: 0.9496\n",
      "Epoch 43/50\n",
      "22392/22392 [==============================] - 12s 547us/sample - loss: 0.0805 - accuracy: 0.9727 - val_loss: 0.2127 - val_accuracy: 0.9496\n",
      "Epoch 44/50\n",
      "22392/22392 [==============================] - 12s 550us/sample - loss: 0.0747 - accuracy: 0.9753 - val_loss: 0.2151 - val_accuracy: 0.9478\n",
      "Epoch 45/50\n",
      "22392/22392 [==============================] - 12s 544us/sample - loss: 0.0779 - accuracy: 0.9740 - val_loss: 0.2125 - val_accuracy: 0.9505\n",
      "Epoch 46/50\n",
      "22392/22392 [==============================] - 12s 548us/sample - loss: 0.0735 - accuracy: 0.9758 - val_loss: 0.2147 - val_accuracy: 0.9512\n",
      "Epoch 47/50\n",
      "22392/22392 [==============================] - 12s 545us/sample - loss: 0.0742 - accuracy: 0.9737 - val_loss: 0.2159 - val_accuracy: 0.9514\n",
      "Epoch 48/50\n",
      "22392/22392 [==============================] - 12s 548us/sample - loss: 0.0689 - accuracy: 0.9773 - val_loss: 0.2066 - val_accuracy: 0.9512\n",
      "Epoch 49/50\n",
      "22392/22392 [==============================] - 12s 547us/sample - loss: 0.0679 - accuracy: 0.9764 - val_loss: 0.2133 - val_accuracy: 0.9518\n",
      "Epoch 50/50\n",
      "22392/22392 [==============================] - 12s 545us/sample - loss: 0.0676 - accuracy: 0.9770 - val_loss: 0.2113 - val_accuracy: 0.9516\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "opt = Adam(lr=1e-3, epsilon=1e-4)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#Adam\n",
    "def step_scheduler(epoch, lr):\n",
    "    return 1e-3 - 2e-5*epoch\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=128, epochs=50,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    callbacks=[LearningRateScheduler(step_scheduler, verbose=0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Epoch 40/50\n",
    "22392/22392 [==============================] - 12s 551us/sample - loss: 0.0936 - accuracy: 0.9691 - val_loss: 0.2047 - val_accuracy: 0.9489\n",
    "Epoch 41/50\n",
    "22392/22392 [==============================] - 12s 549us/sample - loss: 0.0863 - accuracy: 0.9713 - val_loss: 0.2121 - val_accuracy: 0.9471\n",
    "Epoch 42/50\n",
    "22392/22392 [==============================] - 12s 545us/sample - loss: 0.0867 - accuracy: 0.9717 - val_loss: 0.2081 - val_accuracy: 0.9496\n",
    "Epoch 43/50\n",
    "22392/22392 [==============================] - 12s 547us/sample - loss: 0.0805 - accuracy: 0.9727 - val_loss: 0.2127 - val_accuracy: 0.9496\n",
    "Epoch 44/50\n",
    "22392/22392 [==============================] - 12s 550us/sample - loss: 0.0747 - accuracy: 0.9753 - val_loss: 0.2151 - val_accuracy: 0.9478\n",
    "Epoch 45/50\n",
    "22392/22392 [==============================] - 12s 544us/sample - loss: 0.0779 - accuracy: 0.9740 - val_loss: 0.2125 - val_accuracy: 0.9505\n",
    "Epoch 46/50\n",
    "22392/22392 [==============================] - 12s 548us/sample - loss: 0.0735 - accuracy: 0.9758 - val_loss: 0.2147 - val_accuracy: 0.9512\n",
    "Epoch 47/50\n",
    "22392/22392 [==============================] - 12s 545us/sample - loss: 0.0742 - accuracy: 0.9737 - val_loss: 0.2159 - val_accuracy: 0.9514\n",
    "Epoch 48/50\n",
    "22392/22392 [==============================] - 12s 548us/sample - loss: 0.0689 - accuracy: 0.9773 - val_loss: 0.2066 - val_accuracy: 0.9512\n",
    "Epoch 49/50\n",
    "22392/22392 [==============================] - 12s 547us/sample - loss: 0.0679 - accuracy: 0.9764 - val_loss: 0.2133 - val_accuracy: 0.9518\n",
    "Epoch 50/50\n",
    "22392/22392 [==============================] - 12s 545us/sample - loss: 0.0676 - accuracy: 0.9770 - val_loss: 0.2113 - val_accuracy: 0.9516"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'up': 1898,\n",
       "         'off': 1890,\n",
       "         'right': 1906,\n",
       "         'yes': 1901,\n",
       "         'go': 1888,\n",
       "         'down': 1885,\n",
       "         'left': 1885,\n",
       "         'unknown': 3343,\n",
       "         'no': 1909,\n",
       "         'on': 1881,\n",
       "         'stop': 1910,\n",
       "         'silence': 96})"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "collections.Counter(label_index[np.argmax(y_train, axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_data_generator(batch):\n",
    "    fpaths = glob(os.path.join(test_data_path, '*wav'))\n",
    "    i = 0\n",
    "    for path in fpaths:\n",
    "        if i == 0:\n",
    "            imgs = []\n",
    "            fnames = []\n",
    "        i += 1\n",
    "        rate, samples = wavfile.read(path)\n",
    "        samples = pad_audio(samples)\n",
    "        resampled = signal.resample(samples, int(new_sample_rate / rate * samples.shape[0]))\n",
    "        _, _, specgram = log_specgram(resampled, sample_rate=new_sample_rate)\n",
    "        imgs.append(specgram)\n",
    "        fnames.append(path.split('\\\\')[-1])\n",
    "        if i == batch:\n",
    "            i = 0\n",
    "            imgs = np.array(imgs)\n",
    "            yield fnames, imgs\n",
    "    if i < batch:\n",
    "        imgs = np.array(imgs)\n",
    "        yield fnames, imgs\n",
    "    raise StopIteration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.03% -0.3 seconds left\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "generator raised StopIteration",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-141-ffebe8cde74f>\u001b[0m in \u001b[0;36mtest_data_generator\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;32myield\u001b[0m \u001b[0mfnames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimgs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-142-095451d92729>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m128\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mfnames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimgs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest_data_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mpredicts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mpredicts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredicts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: generator raised StopIteration"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "\n",
    "index = []\n",
    "results = []\n",
    "t0 = datetime.datetime.now()\n",
    "i = 1\n",
    "b = 128\n",
    "\n",
    "for fnames, imgs in test_data_generator(b):\n",
    "    predicts = model.predict(imgs)\n",
    "    predicts = np.argmax(predicts, axis=1)\n",
    "    predicts = [label_index[p] for p in predicts]\n",
    "    index.extend(fnames)\n",
    "    results.extend(predicts)\n",
    "    delta = datetime.datetime.now() - t0\n",
    "    clear_output(wait=True)\n",
    "    print('%.2f%% %.1f seconds left' % (b*i/1585.38, delta.total_seconds()*(158538/b/i-1)))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['fname', 'label'])\n",
    "df['fname'] = index\n",
    "df['label'] = results\n",
    "df.to_csv(os.path.join(out_path, 'submission.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unknown    67155\n",
       "on         12437\n",
       "right      11284\n",
       "no          9058\n",
       "go          8344\n",
       "silence     8034\n",
       "left        7624\n",
       "up          7575\n",
       "off         7521\n",
       "down        6667\n",
       "yes         6465\n",
       "stop        6374\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
